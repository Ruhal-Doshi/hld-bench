# HLD-Bench Model Configuration
#
# Define which models to benchmark. Each entry needs:
#   id:          Unique identifier (used in CLI --model flag and output dirs)
#   provider:    Built-in: openai, anthropic, gemini
#                Custom providers fall back to OpenAI-compatible API
#   model:       Model name passed to the provider API
#   displayName: Human-readable name for reports
#   envVar:      (optional) Custom env var for API key
#                Auto-resolved for built-in providers (OPENAI_API_KEY, etc.)
#

models:
  # ── OpenAI Frontier ─────────────────────────────────────────
  - id: gpt-5.2
    provider: openai
    model: gpt-5.2
    displayName: "GPT-5.2"

  - id: gpt-5-mini
    provider: openai
    model: gpt-5-mini
    displayName: "GPT-5 Mini"

  - id: gpt-5-nano
    provider: openai
    model: gpt-5-nano
    displayName: "GPT-5 Nano"

  - id: gpt-5.2-pro
    provider: openai
    model: gpt-5.2-pro
    displayName: "GPT-5.2 Pro"

  - id: gpt-5
    provider: openai
    model: gpt-5
    displayName: "GPT-5"

  - id: gpt-4.1
    provider: openai
    model: gpt-4.1
    displayName: "GPT-4.1"

  # ── Anthropic ───────────────────────────────────────────────
  - id: claude-opus-4-6
    provider: anthropic
    model: claude-opus-4-6
    displayName: "Claude Opus 4.6"

  - id: claude-sonnet-4-5
    provider: anthropic
    model: claude-sonnet-4-5
    displayName: "Claude Sonnet 4.5"

  - id: claude-haiku-4-5
    provider: anthropic
    model: claude-haiku-4-5
    displayName: "Claude Haiku 4.5"

  - id: claude-sonnet-4
    provider: anthropic
    model: claude-sonnet-4-20250514
    displayName: "Claude Sonnet 4"

  # ── Google Gemini ───────────────────────────────────────────
  - id: gemini-3-pro-preview
    provider: gemini
    model: gemini-3-pro-preview
    displayName: "Gemini 3 Pro Preview"

  - id: gemini-3-flash-preview
    provider: gemini
    model: gemini-3-flash-preview
    displayName: "Gemini 3 Flash Preview"

  - id: gemini-2.5-pro
    provider: gemini
    model: gemini-2.5-pro
    displayName: "Gemini 2.5 Pro"

  - id: gemini-2.0-flash
    provider: gemini
    model: gemini-2.0-flash
    displayName: "Gemini 2.0 Flash"

  # ── Custom provider example (uncomment to use) ─────────────
  # - id: deepseek-v3
  #   provider: openai          # DeepSeek uses OpenAI-compatible API
  #   model: deepseek-chat
  #   displayName: "DeepSeek V3"
  #   envVar: DEEPSEEK_API_KEY  # Custom env var

  # ── OpenRouter (open-source & frontier models) ─────────────
  - id: minimax-m2.5
    provider: openrouter
    model: minimax/minimax-m2.5
    displayName: "MiniMax M2.5"

  - id: glm-5
    provider: openrouter
    model: z-ai/glm-5
    displayName: "GLM-5"

  - id: qwen3-max-thinking
    provider: openrouter
    model: qwen/qwen3-max-thinking
    displayName: "Qwen3 Max Thinking"

  - id: kimi-k2.5
    provider: openrouter
    model: moonshotai/kimi-k2.5
    displayName: "Kimi K2.5"
